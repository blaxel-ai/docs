---

title: 'OpenAI Agents'

description: 'Learn how to leverage Blaxel with OpenAI Agents framework.'

---

You can deploy your [OpenAI Agents](https://platform.openai.com/docs/guides/agents) projects to Blaxel with minimal code editing (and zero configuration), enabling you to use [Serverless Deployments](../Infrastructure/Global-Inference-Network), [Agentic Observability](../Observability/Overview), [Policies](../Model-Governance/Policies), and more.

## Get started with OpenAI Agents on Blaxel

To get started with OpenAI Agents SDK on Blaxel:

- if you already have an agent built with OpenAI Agents, adapt your code with [Blaxel SDK commands](../Agents/Develop-an-agent) to connect to [MCP servers](../Functions/Overview), [LLMs](../Models/Overview) and [other agents](../Agents/Overview).
- clone one of our Agents SDK [example templates](https://github.com/blaxel-templates) and deploy it by connecting to your git provider via the Blaxel console.
- or initialize an example project with OpenAI Agents by using the following Blaxel CLI command and selecting the *OpenAI Agents hello world:*

```bash
bl create-agent-app myagent
```

[Deploy](../Agents/Deploy-an-agent) it by running:

```bash
bl deploy
```

<Card title="Explore our template gallery" icon="up-right-from-square" href="https://github.com/blaxel-templates">
Browse Agents SDK agents and deploy them with Blaxel.
</Card>

## Develop with OpenAI Agents using Blaxel features

While building your agent with OpenAI Agents SDK, use Blaxel [SDK](../sdk-reference/introduction) to connect to resources already hosted on Blaxel:

- [MCP servers](../Functions/Overview)
- [LLMs](../Models/Overview)
- [other agents](../Agents/Overview)

### Connect to MCP servers

Connect to [MCP servers](../Functions/Overview) using the Blaxel SDK to access pre-built or custom tool servers hosted on Blaxel. This eliminates the need to manage server connections yourself, with credentials stored securely on the platform.

Run the following command to retrieve tools in OpenAI Agents format:

<CodeGroup>

```python Python

from blaxel.openai import bl_tools

await bl_tools(['mcp-server-name'])

```

</CodeGroup>

### Connect to LLMs

Connect to [LLMs](../Models/Overview) hosted on Blaxel using the SDK to avoid managing model API connections yourself. All credentials remain securely stored on the platform.

<CodeGroup>

```python Python

from blaxel.openai import bl_model

model = await bl_model("model-api-name")

```

</CodeGroup>

### Connect to other agents

Connect to other agents hosted on Blaxel from your code by using the [Blaxel SDK](../sdk-reference/introduction). This allows for multi-agent chaining without managing connections yourself. This command is independent of the framework used to build the agent.

<CodeGroup>

```python Python

from blaxel.core.agents import bl_agent

response = await bl_agent("agent-name").run(input);

```

</CodeGroup>

### Host your agent on Blaxel

You can [deploy](../Agents/Deploy-an-agent) your agent on Blaxel, enabling you to use [Serverless Deployments](../Infrastructure/Global-Inference-Network), [Agentic Observability](../Observability/Overview), [Policies](../Model-Governance/Policies), and more. This command is independent of the framework used to build the agent.

Either run the following CLI command from the root of your agent repository.

```bash
bl deploy
```

Or [connect a GitHub repository to Blaxel](../Agents/Github-integration) for automatic deployments every time you push on *main*.