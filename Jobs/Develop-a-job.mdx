---

title: 'Development guide'

description: 'Run custom AI batch jobs on Blaxel.'

---

Jobs allow you to run many AI tasks in parallel using batch processing. Read the [introduction for a lexicon on jobs, tasks, and executions](Overview).

## Quickstart

<Warning>It is required to have *npm* (TypeScript) *or uv* (Python) installed to use the following command.</Warning>

You can quickly **initialize a new job from scratch** by using the CLI command `bl new job`.

```bash
bl new job
```

This will create a pre-scaffolded local directory where your entire code can be added. In the generated folder, you'll find a boilerplate job with multiple steps in the entrypoint file `src/index.ts` / `src/main.py`.

The template used to generate the boilerplate job is available in Blaxel's public GitHub repository ([TypeScript](https://github.com/blaxel-templates/template-jobs-ts) / [Python](https://github.com/blaxel-templates/template-jobs-py)).

Start the job locally:

```bash
# Run the job with a sample batch file
bl run job <<JOB-NAME>> --local --file batches/sample-batch.json

# Or directly with --data argument
bl run job <<JOB-NAME>> --local --data '{"tasks": [{"name": "John"}]}'

# Or without blaxel CLI
pnpm start --name John
```

<Card title="Deploy a job" icon="server" href="/Jobs/Deploy-a-job">
Learn how to deploy your AI batch jobs on Blaxel as a serverless auto-scalable endpoint.
</Card>
