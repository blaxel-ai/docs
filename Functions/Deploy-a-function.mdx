---

title: 'Deploy custom MCP servers'

description: 'Host your custom MCP Servers on Blaxel in a few clicks.'

---

Blaxel provides a serverless infrastructure to instantly deploy MCP servers. You receive a global inference endpoint for each deployment, and your workloads are served optimally to dramatically accelerate cold-start and latency. The main way to deploy an MCP server on Blaxel is by **using Blaxel CLI.**

## Deploy an MCP server with Blaxel CLI

This section assumes you have developed the MCP server locally, as explained [in this documentation](Create-MCP-server), and are ready to deploy it. 

### Serve locally

You can serve the MCP server locally in order to make the main function in `server.ts` / `server.py` available on a local endpoint. 

Run the following command to serve the MCP server:

```bash
bl serve
```

You can then create an MCP Client to communicate with your server. When testing locally, communication happens over stdio, but when deployed on Blaxel, your server will use WebSockets instead. 

Add the flag `--hotreload`  to get live changes.

```bash
bl serve --hotreload
```

### Deploy on production

You can deploy the MCP server in order to make it **available on a global hosted endpoint**. When deploying to Blaxel, you get a dedicated endpoint that enforces your [deployment policies](../Model-Governance/Policies).

Run the following command to build and deploy the MCP server on Blaxel:

```bash
bl deploy
```

You can now [connect to the MCP server](Invoke-functions) either from an agent on Blaxel (using the Blaxel SDK), or from an external client that supports WebSockets transport. 

<CodeGroup>

```typescript In TypeScript

import { blTools } from "@blaxel/sdk";

// Retrieve tools (in whichever framework format):
const tools = blTools(['blaxel-search']).ToVercelAI();
// or
const tools = blTools(['blaxel-search']).ToLangChain();
// or
const tools = blTools(['blaxel-search']).ToLlamaIndex();
// or

// …
```

```python In Python

from blaxel.tools import bl_tools

# Retrieve tools (in whichever framework format):
await bl_tools(['blaxel-search']).to_pydantic();
# or
await bl_tools(['blaxel-search']).to_langchain();
# or
await bl_tools(['blaxel-search']).to_llamaindex();
#or

# …
```

</CodeGroup>

<Card title="Connect to an MCP server" icon="bolt" href="/Functions/Invoke-functions">
Learn how to run invocation requests on your MCP server. 
</Card>

### Customize an MCP server deployment

You can set custom parameters for an MCP server deployment (e.g. specify the server name, etc.) in the `blaxel.toml` file at the root of your directory.

This file is used to configure the deployment of the MCP server on Blaxel. It's not mandatory, but it allows you to customize the deployment.

```toml
name = "my-mcp-server"
workspace = "my-workspace"
type = "function"

[env]
DEFAULT_CITY = "San Francisco"
```

- `name`, `workspace`, and `type` fields are optional and serve as default values. Any bl command run in the folder will use these defaults rather than prompting you for input.
- `[env]` section defines environment variables that the MCP server can access via the SDK. Note that these are NOT [secrets](../Agents/Variables-and-secrets).

<AccordionGroup>
<Accordion title="Define entrypoints in Python" icon="python">

Additionally, when developing in Python, you can define an `[entrypoint]` section to specify how Blaxel is going to start your server. 

```toml
...

[entrypoint]
prod = ".venv/bin/python3 src/server.py"
dev = "npx nodemon --exec uv run python src/server.py"

...
```

- `prod`:  this is the command that will be used to serve your MCP server

```bash
.venv/bin/python3 src/server.py
```

- `dev`: same as prod in dev mode, it will be used with the command `--hotreload`. Example:

```bash
npx nodemon --exec uv run python src/server.py
```

This `entrypoint` section is optional. If not specified, Blaxel will automatically detect in the MCP server’s content and configure your server’s startup settings.

</Accordion>

<Accordion title="Define entrypoints in TypeScript" icon="js">

In TypeScript, entrypoints are managed in the `scripts` in the `package.json` file at the root of the directory.

- `scripts.start` : start the server locally through the TypeScript command, to avoid having to build the project when developing.
- `scripts.build` : build the project. It is done automatically when deploying.
- `scripts.prod` : start the server remotely on Blaxel from the dist folder, the project needs to be have been built before.
- `scripts.dev` : same as start, but with hotreload. It's useful when developing locally, each file change is reflected immediately.

The remaining fields in *package.json* follow standard JavaScript/TypeScript project conventions. Feel free to add any dependencies you need, but keep in mind that devDependencies are only used during the build process and are removed afterwards.
</Accordion>
</AccordionGroup>

## Overview of deployment life-cycle

### Choosing the infrastructure generation

Blaxel offers two [infrastructure generations](../Infrastructure/Gens). When deploying a workload, you can select between *Mk 2 infrastructure*—which provides stable, globally distributed container-based workloads—and *Mk 3* (in Alpha), which delivers ultra-fast cold starts. Choose the generation that best fits your specific requirements.

### Maximum runtime

Deployed MCP servers have a runtime limit after which executions time out. This timeout duration is determined by your chosen [infrastructure generation](../Infrastructure/Gens). For Mk 2 generation, the **default timeout is 5 minutes**, but this can be increased up to 60 minutes depending on your workspace’s quota.

### Manage revisions

As you iterate on your software development, you will need to update the version of a function that is currently deployed and used by your consumers. Every time you build a new version of your function, this creates a **revision**. Blaxel stores the 10 latest revisions for each object. 

![image.png](Deploy-a-function/image.png)

Revisions are atomic builds of your deployment that can be either deployed (accessible via the inference endpoint) or not. This system enables you to:

- **rollback a deployment** to its exact state from an earlier date
- create a revision without immediate deployment to **prepare for a future release**
- implement progressive rollout strategies, such as **canary deployments**

Important: Revisions are not the same as versions. You cannot use revisions to return to a previous configuration and branch off from it. For version control, use your preferred system (such as GitHub) alongside Blaxel.

Deployment revisions are updated following a **blue-green** paradigm. The Global Inference Network will wait for the new revision to be completely up and ready before routing requests to the new deployment. You can also set up a **canary deployment** to split traffic between two revisions (maximum of two).

![image.png](../Agents/Deploy-an-agent/image%201.png)

<Note>When making a deployment using Blaxel CLI (`bl deploy`), the new traffic routing depends on the `--traffic` option. Without this option specified, Blaxel will automatically deploy the new revision with full traffic (100%) if the previous deployment was the latest revision. Otherwise, it will create the revision without deploying it (0% traffic).</Note>

<Card title="Invoke functions" icon="bolt" href="/Functions/Invoke-functions">
Learn how to run invocation requests on your function. 
</Card>